{"is_source_file": true, "format": "Python", "description": "This file initializes an Agent with a specific Llama model and demonstrates how to generate and print a response to a prompt, specifically for streaming output.", "external_files": ["agno.agent", "agno.models.meta"], "external_methods": ["Agent.__init__", "Agent.run", "Agent.print_response", "Llama.__init__"], "published": [], "classes": [{"name": "Agent", "description": "An agent that interacts with a language model, capable of running prompts and printing responses."}, {"name": "Llama", "description": "A class representing the Llama language model configuration."}], "methods": [{"name": "Agent.__init__", "description": "Initializes an Agent with a specified model and options."}, {"name": "Agent.run", "description": "Executes a prompt and returns an iterator over the response stream."}, {"name": "Agent.print_response", "description": "Prints the response to a prompt directly to the terminal."}, {"name": "Llama.__init__", "description": "Constructs a Llama model configuration with specified parameters."}], "calls": ["Agent.print_response", "Agent.run"], "search-terms": ["basic_stream", "Llama model initialization", "streaming response", "agent interaction"], "state": 2, "file_id": 1466, "knowledge_revision": 3740, "git_revision": "c4cabc851178c113c4f14aa2047e2d99383e83c5", "ctags": [], "filename": "cookbook/models/meta/llama/basic_stream.py", "hash": "c0429339cae41c516c68a7d2447904ef", "format-version": 4, "code-base-name": "https://github.com/codesperfect/agno.git:main", "revision_history": [{"3740": "c4cabc851178c113c4f14aa2047e2d99383e83c5"}]}