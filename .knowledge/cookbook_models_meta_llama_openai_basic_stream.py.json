{"is_source_file": true, "format": "Python", "description": "This file sets up an agent using the agno library with a specific LlamaOpenAI model and demonstrates how to print a response to a prompt, likely for streaming output.", "external_files": ["agno.agent", "agno.models.meta"], "external_methods": ["Agent", "RunResponse", "LlamaOpenAI", "agent.print_response"], "published": [], "classes": [{"name": "Agent", "description": "Represents an agent configured with a specific model, capable of running prompts and printing responses."}, {"name": "LlamaOpenAI", "description": "Model class representing a Llama OpenAI model with specific configuration."}], "methods": [{"name": "print_response", "description": "Method to print the response of the agent for a given prompt, with streaming enabled."}], "calls": ["agent.print_response"], "search-terms": ["llama_openai", "agent setup", "streaming response", "print_response", "model configuration"], "state": 2, "file_id": 1482, "knowledge_revision": 3742, "git_revision": "c4cabc851178c113c4f14aa2047e2d99383e83c5", "ctags": [], "filename": "cookbook/models/meta/llama_openai/basic_stream.py", "hash": "d17d118eeb93c369590d42e6ba5461fd", "format-version": 4, "code-base-name": "https://github.com/codesperfect/agno.git:main", "revision_history": [{"3742": "c4cabc851178c113c4f14aa2047e2d99383e83c5"}]}