{"is_source_file": true, "format": "Python", "description": "This file sets up an asynchronous interaction with an AI agent using the 'Agent' class from the 'agno.agent' module, specifically to generate and print a horror story using a Llama model.", "external_files": ["agno.agent", "agno.models.meta"], "external_methods": ["Agent.__init__", "Agent.arun", "Agent.aprint_response", "Llama.__init__"], "published": [], "classes": [{"name": "Agent", "description": "Represents an AI agent capable of generating responses based on a model."}, {"name": "Llama", "description": "Model class representing the Llama language model."}], "methods": [{"name": "arun", "description": "Asynchronously runs the agent to generate a response to a prompt, optionally streaming output."}, {"name": "aprint_response", "description": "Asynchronously prints the response generated by the agent for a given prompt."}], "calls": ["asyncio.run", "agent.arun", "agent.aprint_response"], "search-terms": ["asyncio", "Llama model", "agent interaction", "async response generation", "streaming response"], "state": 2, "file_id": 1469, "knowledge_revision": 3736, "git_revision": "c4cabc851178c113c4f14aa2047e2d99383e83c5", "ctags": [], "filename": "cookbook/models/meta/llama/async_basic_stream.py", "hash": "dddeb15f25e28d34f09eb4ec2faccf57", "format-version": 4, "code-base-name": "https://github.com/codesperfect/agno.git:main", "revision_history": [{"3736": "c4cabc851178c113c4f14aa2047e2d99383e83c5"}]}