{"is_source_file": true, "format": "Python", "description": "This file defines a Python class 'Llama' for interacting with Llama models via an API, including methods for synchronous and asynchronous requests, streaming, and response parsing.", "external_files": ["llama_api_client", "llama_api_client.types.create_chat_completion_response", "llama_api_client.types.create_chat_completion_response_stream_chunk", "llama_api_client.types.message_text_content_item", "agno.exceptions", "agno.models.base", "agno.models.message", "agno.models.response", "agno.utils.log", "agno.utils.models.llama"], "external_methods": ["getenv", "log_error", "log_debug", "log_warning", "format_message"], "published": ["Llama"], "classes": [{"name": "Llama", "description": "A class for interacting with Llama models using the Llama API and SDK, supporting synchronous, asynchronous, and streaming requests, as well as response parsing."}], "methods": [{"name": "_get_client_params", "description": "Constructs and returns the client parameters dictionary, fetching API key from environment if not set."}, {"name": "get_client", "description": "Returns a cached or new instance of the Llama API client."}, {"name": "get_async_client", "description": "Returns a cached or new instance of the asynchronous Llama API client."}, {"name": "get_request_params", "description": "Generates request parameters for API calls, including optional tools and response format."}, {"name": "to_dict", "description": "Serializes the model instance to a dictionary, including its configuration."}, {"name": "invoke", "description": "Performs a synchronous chat completion request to the Llama API."}, {"name": "ainvoke", "description": "Performs an asynchronous chat completion request to the Llama API."}, {"name": "invoke_stream", "description": "Performs a streaming chat completion request synchronously, yielding response chunks."}, {"name": "ainvoke_stream", "description": "Performs an asynchronous streaming chat completion request, yielding response chunks."}, {"name": "parse_tool_calls", "description": "Parses tool call data from the API response into a list of call dictionaries."}, {"name": "parse_provider_response", "description": "Parses a standard API response into a ModelResponse object."}, {"name": "parse_provider_response_delta", "description": "Parses a streaming API response chunk into a ModelResponse object."}], "calls": ["getenv", "log_error", "log_debug", "log_warning", "format_message", "LlamaAPIClient", "AsyncLlamaAPIClient"], "search-terms": ["Llama", "llama_api_client", "streaming", "async", "Model", "chat completion"], "state": 2, "file_id": 276, "knowledge_revision": 2543, "git_revision": "69e8f9dc474e69f2d3863442c4c1c6824ca37f08", "ctags": [], "filename": "libs/agno/agno/models/meta/llama.py", "hash": "e30eba9e7690078742c5a5a4e941943d", "format-version": 4, "code-base-name": "https://github.com/codesperfect/agno.git:main", "revision_history": [{"2543": "69e8f9dc474e69f2d3863442c4c1c6824ca37f08"}]}