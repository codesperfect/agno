{"is_source_file": true, "format": "Python", "description": "This file sets up an asynchronous interaction with an AI agent using the 'Agent' class from the 'agno.agent' module, specifically to generate and print a horror story using a Llama model.", "external_files": ["agno.agent", "agno.models.meta"], "external_methods": ["Agent", "RunResponse", "LlamaOpenAI", "agent.arun", "agent.aprint_response"], "published": [], "classes": [{"name": "Agent", "description": "Represents an AI agent capable of generating responses based on a specified model."}, {"name": "RunResponse", "description": "Represents the response from the agent's run method."}, {"name": "LlamaOpenAI", "description": "Model configuration class for Llama OpenAI models."}], "methods": [{"name": "arun", "description": "Asynchronously runs the agent to generate a response based on a prompt, with streaming enabled."}, {"name": "aprint_response", "description": "Asynchronously prints the response generated by the agent for a given prompt."}], "calls": ["asyncio.run", "agent.arun", "agent.aprint_response"], "search-terms": ["asyncio", "LlamaOpenAI", "agent.aprint_response", "agent.arun", "async_basic_stream"], "state": 2, "file_id": 1485, "knowledge_revision": 3753, "git_revision": "c4cabc851178c113c4f14aa2047e2d99383e83c5", "ctags": [], "filename": "cookbook/models/meta/llama_openai/async_basic_stream.py", "hash": "42956714182aab690151f463744b8a79", "format-version": 4, "code-base-name": "https://github.com/codesperfect/agno.git:main", "revision_history": [{"3753": "c4cabc851178c113c4f14aa2047e2d99383e83c5"}]}