{"is_source_file": true, "format": "Python", "description": "This file defines a Python class 'Ollama' for interacting with Ollama models, including methods for client management, message formatting, request handling, and response parsing. It is part of a larger project involving AI model integrations.", "external_files": ["agnomodels.base", "agnomodels.message", "agnomodels.response", "agnoutils.log", "ollama", "ollama._types"], "external_methods": ["log_debug", "log_warning"], "published": ["Ollama"], "classes": [{"name": "Ollama", "description": "A class for interacting with Ollama models, providing methods for client management, message formatting, request invocation, and response parsing."}], "methods": [{"name": "_get_client_params", "description": "Constructs a dictionary of client parameters based on instance attributes."}, {"name": "get_client", "description": "Returns an Ollama client instance, creating it if necessary."}, {"name": "get_async_client", "description": "Returns an asynchronous Ollama client instance, creating it if necessary."}, {"name": "get_request_params", "description": "Generates request parameters for API calls, including optional tools."}, {"name": "to_dict", "description": "Serializes the model instance to a dictionary, including relevant attributes."}, {"name": "_format_message", "description": "Formats a Message object into a dictionary suitable for Ollama API."}, {"name": "_prepare_request_kwargs_for_invoke", "description": "Prepares request arguments, including structured output schema if specified."}, {"name": "invoke", "description": "Performs a synchronous chat request to the Ollama API with provided messages."}, {"name": "ainvoke", "description": "Performs an asynchronous chat request to the Ollama API with provided messages."}, {"name": "invoke_stream", "description": "Streams a chat request to the Ollama API, yielding chunks of response."}, {"name": "ainvoke_stream", "description": "Asynchronously streams a chat request to the Ollama API, yielding response chunks."}, {"name": "parse_provider_response", "description": "Parses the response from the Ollama API into a ModelResponse object."}, {"name": "parse_provider_response_delta", "description": "Parses incremental response delta from the Ollama API into a ModelResponse object."}], "calls": ["OllamaClient", "AsyncOllamaClient", "log_debug", "log_warning"], "search-terms": ["Ollama", "chat.py", "Ollama class", "model interaction", "client management", "message formatting", "response parsing", "async client", "streaming chat"], "state": 2, "file_id": 257, "knowledge_revision": 2527, "git_revision": "7be3f1b991ce63c06a4f1f5b80ebfaa88aa24e69", "ctags": [], "filename": "libs/agno/agno/models/ollama/chat.py", "hash": "263a972869a6af955022ad957a2d152e", "format-version": 4, "code-base-name": "https://github.com/codesperfect/agno.git:main", "revision_history": [{"2527": "7be3f1b991ce63c06a4f1f5b80ebfaa88aa24e69"}]}